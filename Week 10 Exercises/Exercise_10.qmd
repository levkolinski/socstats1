---
title: "Exercise_10"
author: "Lev Kolinski"
format: html
editor: visual
---

```{r include=FALSE}
library(tidyverse, warn.conflicts=FALSE)
theme_set(theme_light(base_family = "Optima"))

library(modelsummary)
library(broom)
library(gt)

library(gssr)
gss18 <- gss_get_yr(2018) 

d <- gss18 |> 
  select(attend, polviews, cappun, degree) |> 
  haven::zap_missing() |> 
  mutate(across(!degree, haven::zap_labels)) |> 
  mutate(degree = haven::as_factor(degree)) |> 
  mutate(
    weekly = if_else(attend >= 7, 1L, 0L),
    polviews = polviews - 4,
    cappun = if_else(cappun == 1, 1L, 0L),
    ) |> 
  mutate(conservative = as.integer(polviews > 0)) |> 
  drop_na() 

```

# 10.3.1 Exercise

-   `cappun ~ polviews + weekly + polviews:weekly`

```{r}
mod1<-model.matrix(cappun ~ polviews + weekly + polviews:weekly, data=d)
head(mod1)
dim(mod1)
```

This `cappun ~ polviews + weekly + polviews:weekly`model yields a 2102 x 4 matrix with an intercept column, a polviews column, a weekly column, and a polviews:weekly column.

-   `cappun ~ polviews * weekly`

```{r}
mod2<-model.matrix(cappun ~ polviews * weekly, data=d)
head(mod2)
dim(mod2)
```

This `cappun ~ polviews * weekly` model yields a 2102 x 4 matrix with an intercept column, polviews column, a weekly column, and a polviews:weekly column.

-   `cappun ~ degree`

```{r}
mod3<-model.matrix(cappun ~ degree, data=d)
head(mod3)
dim(mod3)
```

This `cappun ~ degree` model yields a 2102 x 5 matrix with an intercept column, and then columns for each factor of the degree variable: "degreehigh school", "degreeassociate/junior college", "degreebachelor's", and "degreegraduate". "Less than high school" is the reference group.

# 10.3.2 Exercise

```{r}
mod1 <- glm(cappun ~ conservative + weekly, data = d, family = "binomial")
mod2 <- glm(cappun ~ conservative * weekly, data = d, family = "binomial")
mod3 <- glm(cappun ~ polviews + weekly, data = d, family = "binomial")
mod4 <- glm(cappun ~ polviews * weekly, data = d, family = "binomial")

msummary(list(mod1, mod2, mod3, mod4), output = "gt") |> 
  opt_table_font(font = "Optima")
```

## Comparing models with AIC and BIC

### AIC

Of all 4 models, the AIC of `mod4` is the lowest at 2609.423, indicating that it fits the data the best. However, it is very similar to the AIC of `mod3` (2610.704). Thus, it is unlikely that the interaction term between `polviews` and `weekly` significantly impacts the out-of-sample deviance.

The AICs of `mod3` and `mod4` are both lower than the AICs of `mod1` (2698.224) and `mod2` (2698.924), which indicates that the inclusion of the `polviews` predictor variable is more important to fitting the data and minimizing out-of-sample deviance than the `conservative` variable. This is true whether we include an effect term between `conservative` and `weekly` or not.

### BIC

BIC is similar to AIC, but the AIC statistic tends to penalize complex models less (according to this [source](https://machinelearningmastery.com/probabilistic-model-selection-measures/#:~:text=Compared%20to%20the%20BIC%20method,to%20pick%20more%20complex%20models.)). The BIC of `mod3` is the lowest at 2627.656, indicating that it fits the data the best. However, it is very similar to the BIC of `mod4`, so it is unlikely that the interaction term between `polviews` and `weekly` significantly impacts the model fit.

The BICs of `mod3` and `mod4` are both lower than the AICs of `mod1` (2715.176) and `mod2` (2721.526), which indicates that the inclusion of the `polviews` predictor variable is more important to fitting the data than the `conservative` variable. This is true whether we include an effect term between `conservative` and `weekly` or not.

## Interpreting Intercepts

```{r}
msummary(list(mod1, mod2, mod3, mod4), gof_map = "none", output = "gt") |> 
  opt_table_font(font = "Optima")
```

The intercept of all models represents the log-odds of the dependent variable `cappun` being 1 (i.e. respondent favors capital punishment) when all predictor variables are 0. In other words, the intercept is the baseline log-odds of favoring capital punishment when the predictors are at their reference levels. Looking at the models individually:

-   In `mod1`, the intercept value, 0.358, is the log-odds of `cappun` being 1 when the respondent is NOT conservative and does NOT attend religious services weekly. As a probability, this log-odds value = 0.5886.

-   In `mod2`, there is an interaction term that allows the model to capture the combined effect of `conservative` and `weekly` on the response variable, `cappun`. The intercept value, 0.341, is the log-odds of `cappun` being 1 when the respondent is NOT conservative, does NOT attend religious services weekly, and the interaction of `conservative` and `weekly` is zero. As a probability, this log-odds value = 0.5844.

-   In `mod3`, the intercept value, 0.666, is the log-odds of `cappun` being 1 when the respondent is moderate (`polviews`=0) and does NOT attend religious services weekly. As a probability, this log-odds value = 0.6606.

-   In `mod4`, there is an interaction term that allows the model to capture the combined effect of `polviews` and `weekly` on the response variable, `cappun`. The intercept value, 0.677, is the log-odds of `cappun` being 1 when the respondent is moderate (`polviews` =0), does NOT attend religious services weekly, and the interaction of `polviews` and `weekly` is zero. As a probability, this log-odds value = 0.6631.

## Looking at mod4...

...what is the predicted probability that a "slightly conservative" individual that attends religious ceremonies weekly favors capital punishment?

```{r}
polviews <- 1 #slightly conservative = 1
weekly <- 1 # attends services weekly =1
 
log_odds <- coef(mod4)["(Intercept)"] + 
  coef(mod4)["polviews"]*polviews + 
  coef(mod4)["weekly"]*weekly + 
  coef(mod4)["polviews:weekly"]*polviews*weekly

# exponentiate, ratio to get probability
predicted_probability <- 1 / (1 + exp(-log_odds))
predicted_probability
```

The predicted probability that a slightly conservative individual that attends religious ceremonies weekly favors capital punishment is **0.629, or 62.9%.**

# 10.3.3 Exercise

## Transforming `polviews`

```{r}
d2 <- d |> 
  mutate(polviews2 = factor(case_when(
    polviews < 0 ~ "liberal",
    polviews == 0 ~ "moderate",
    polviews > 0 ~ "conservative"
  )))
head(d2)
```

## Fitting the model to different reference categories

Setting "liberal" as reference category

```{r}
d2_liberal_as_reference <- d2 |> 
  mutate(polviews2 = relevel(polviews2, ref = "liberal"))

mod1<-glm(cappun ~ polviews2 + weekly, data=d2_liberal_as_reference, family="binomial")
```

Setting "moderate" as reference category

```{r}
d2_moderate_as_reference <- d2 |> 
  mutate(polviews2 = relevel(polviews2, ref = "moderate"))

mod2<-glm(cappun ~ polviews2 + weekly, data=d2_moderate_as_reference,family="binomial")
```

Setting "conservative" as reference category

```{r}
d2_conservative_as_reference <- d2 |> 
  mutate(polviews2 = relevel(polviews2, ref = "conservative"))

mod3<-glm(cappun ~ polviews2 + weekly, data=d2_conservative_as_reference,family="binomial")
```

## Comparing the model with different reference categories

```{r}
msummary(list(mod1, mod2, mod3), output = "gt") |> 
  opt_table_font(font = "Optima") 
```

The model fits the data with an AIC of 2634.1, regardless of the reference category chosen.

### Interpreting coefficients

With "liberal" as the reference category (`mod1`):

-   $\alpha$ = -0.124

    -   The intercept value, --.124, is the log-odds of `cappun` being 1 when the respondent is liberal and does NOT attend religious services weekly.

-   $\beta_1$ = 1.362

    -   Being conservative increases the log-odds of favoring the death penalty by 1.362

-   $\beta_2$ = 0.894

    -   Being moderate increases the log-odds of favoring the death penalty by 0.894

-   $\beta_3$ = -0.417

    -   Attending religious services weekly decreases the log-odds of favoring the death penalty by 0.417

With "moderate" as the reference category (`mod2`):

-   $\alpha$ = 0.770

    -   The intercept value, 0.770, is the log-odds of `cappun` being 1 when the respondent is moderate and does NOT attend religious services weekly.

-   $\beta_1$ = 0.468

    -   Being conservative increases the log-odds of favoring the death penalty by 0.468

-   $\beta_2$ = -0.894

    -   Being liberal decreases the log-odds of favoring the death penalty by 0.894

-   $\beta_3$ = -0.417

    -   Attending religious services weekly decreases the log-odds of favoring the death penalty by 0.417

With "conservative" as the reference category (`mod3`):

-   $\alpha$ = 1.238

    -   The intercept value, 1.238, is the log-odds of `cappun` being 1 when the respondent is conservative and does NOT attend religious services weekly.

-   $\beta_1$ = -0.468

    -   Being moderate decreases the log-odds of favoring the death penalty by 0.468

-   $\beta_2$ = -1.362

    -   Being liberal decreases the log-odds of favoring the death penalty by 1.362

-   $\beta_3$ = -0.417

    -   Attending religious services weekly decreases the log-odds of favoring the death penalty by 0.417

# 10.3.4 Exercise

::: callout-note
Fill in the conditional probabilities in the following table:

Probability that a respondent favors capital punishment ( $\texttt{cappun} = 1$ )

| `weekly` | `polviews2`  | Saturated Model | Restricted Model |
|----------|--------------|-----------------|------------------|
| 0        | liberal      | **0.460**       | **0.469**        |
| 0        | moderate     | **0.685**       | **0.683**        |
| 0        | conservative | **0.783**       | **0.775**        |
| 1        | liberal      | **0.419**       | **0.368**        |
| 1        | moderate     | **0.579**       | **0.587**        |
| 1        | conservative | **0.678**       | **0.694**        |
:::

Check out my work below:

```{r}
saturated_model <- glm(cappun ~ weekly * polviews2, data = d2, family = "binomial")
restricted_model <- glm(cappun ~ weekly + polviews2, data = d2, family = "binomial")

# Create a df with all combinations of weekly and polviews2
new_data <- expand.grid(weekly = c(0, 1), polviews2 = c("liberal", "moderate", "conservative"))

# Predict probabilities for the saturated model
predicted_probs_saturated <- predict(saturated_model, newdata = new_data, type = "response")

# Predict probabilities for the restricted model
predicted_probs_restricted <- predict(restricted_model, newdata = new_data, type = "response")

# Fill in the table with predicted probabilities
conditional_probabilities <- tibble(
  weekly = new_data$weekly,
  polviews2 = new_data$polviews2,
  Saturated_Model = predicted_probs_saturated,
  Restricted_Model = predicted_probs_restricted
)

conditional_probabilities
```

# 10.3.5 Exercise

## Choosing variables

Outcome variable:

-   `suicide3`: Does respondent think that a person has a right to end their own life if they have dishonored his or her family?
    -   1 = yes
    -   2 = no

Predictor variables:

-   `sex`: Is the respondent male or female?

    -   1 = male

    -   2 = female

-   `madeg`: Respondents mother's level of education ("Less than high school" = reference category)

    -   0 = Less than high school

    -   1 = High School

    -   2 = Associate/Junior College

    -   3 = Bachelor

    -   4 = Graduate

```{r}
d3 <-gss18 |> 
  select(suicide3,sex,madeg) |> 
  haven::zap_missing() |> 
  mutate(across(!madeg, haven::zap_labels)) |> 
  mutate(madeg = haven::as_factor(madeg)) |> 
  mutate(
    approves_suicide = if_else(suicide3 == 1, 1L, 0L),
    male = if_else(sex == 1, 1L,0L),
  ) |> 
  drop_na()

mod1<-glm(approves_suicide ~ male, data=d3, family="binomial")

mod2<-glm(approves_suicide ~ madeg, data=d3, family="binomial")

mod3<-glm(approves_suicide ~ male*madeg, data=d3, family="binomial")
```

## Comparing models

```{r}
msummary(list(mod1, mod2, mod3), output = "gt") |> 
  opt_table_font(font = "Optima")
```

Based on AIC, `mod3` has the best out-of sample preditive accuracy because $AIC_3$\<$AIC_1$\<$AIC_2$. This is likely because the combined predictive powers of `sex`, `madeg`, and the interaction between `sex` and `madeg` on `suicide3` is greater than the predictive power of `sex` or `madeg` alone.

Based on BIC, `mod1` has the lowest penalty terms (and thus is the best model) because $BIC_1$\<$BIC_2$\<$BIC_3$. BIC penalizes the number of parameters more strongly than AIC, which may explain why the most complex model (`mod3`) has the highest BIC but the lowest AIC. According to BIC, `sex` alone is the best predictor of `suicide3`.

## Relationship between outcome and predictors

-   `mod1` : `approves_suicide` \~ `male`

    -   $\alpha$ = -1.999

        -   The intercept value, -1.999, is the log-odds of `approves_suicide` being 1 when the respondent is NOT male.

    -   $\beta_1$ = 0.246

        -   Being male increases the log-odds of favoring the death penalty by 0.246

-   `mod2` : `approves_suicide` \~ `madeg`

    -   $\alpha$ = -2.533

        -   The intercept value, -2.533, is the log-odds of `approves_suicide` being 1 when the the respondent's mother has less than a high school degree

    -   $\beta_1$ = 0.771

        -   Respondent's mother having a high school degree increases the log-odds of favoring the death penalty by 0.771

    -   $\beta_2$ = 0.780

        -   Respondent's mother having an associate/junior college degree increases the log-odds of favoring the death penalty by 0.780

    -   $\beta_3$ = 1.073

        -   Respondent's mother having a bachelors degree increases the log-odds of favoring the death penalty by 1.073

    -   $\beta_4$ = 0.803

        -   Respondent's mother having a graduate degree increases the log-odds of favoring the death penalty by 0.803

-   `mod3` : `approves_suicide` \~ `male`\*`madeg`

    -   $\alpha$ = -2.508

        -   The intercept value, -2.508, is the log-odds of `approves_suicide` being 1 when the respondent's mother has less than a high school degree, the respondent is NOT male, and the interaction term between `male` and `madeg` equals 0.

    -   $\beta_1$ = -0.064

        -   Being male decreases the log-odds of favoring the death penalty by 0.064

    -   $\beta_2$ = 0.625

        -   Respondent's mother having a high school degree increases the log-odds of favoring the death penalty by 0.625

    -   $\beta_3$ = 0.695

        -   Respondent's mother having an associate/junior college degree increases the log-odds of favoring the death penalty by 0.695

    -   $\beta_3$ = 0.846

        -   Respondent's mother having a bachelors degree increases the log-odds of favoring the death penalty by 0.846

    -   $\beta_4$ = 0.716

        -   Respondent's mother having a graduate degree increases the log-odds of favoring the death penalty by 0.716

    -   $\beta_5$ = 0.315

        -   The interaction between the respondent being male AND the respondent's mother having a high school degree increases the log-odds of favoring the death penalty by 0.315

    -   $\beta_6$ = 0.228

        -   The interaction between the respondent being male AND the respondent's mother having an associate/junior college degree increases the log-odds of favoring the death penalty by 0.228

    -   $\beta_7$ = 0.473

        -   The interaction between the respondent being male AND the respondent's mother having a bachelors degree increases the log-odds of favoring the death penalty by 0.473

    -   $\beta_8$ = 0.182

        -   The interaction between the respondent being male AND the respondent's mother having a graduate degree increases the log-odds of favoring the death penalty by 0.182

# 10.3.6 Extra

```{r}
mod<-model.matrix(cappun ~ polviews + weekly + polviews:weekly, data=d)


boot_coef <- replicate(n = 2e3, simplify = FALSE, expr = {
  i <- sample(1:nrow(d), replace = TRUE)
  m <- glm(cappun ~ conservative + weekly, family = "binomial", data = d[i, ])
  coefficients(m)
}) |> bind_rows()

# glimpse(boot_coef)

boot_coef |> 
  pivot_longer(everything(), names_to = "term", values_to = "stat") |> 
  group_by(term) |> 
  summarize(estimate = mean(stat), std.error = sd(stat))

broom::tidy(mod)


# with infer package instead
library(infer)
boot <- d |> 
  specify(cappun ~ weekly + conservative) |> 
  generate(reps = 5000, type = "bootstrap") |> 
  fit(family = "binomial")

boot |> 
  group_by(term) |> 
  summarize(mean = mean(estimate), std.error = sd(estimate))

boot |> 
  visualize(bins = 30)
```
